{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c404a18-1d55-4d16-ade6-f6dca6b9cf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, error=2.579\n",
      ">epoch=1, error=2.461\n",
      ">epoch=2, error=2.367\n",
      ">epoch=3, error=2.296\n",
      ">epoch=4, error=2.247\n",
      ">epoch=5, error=2.214\n",
      ">epoch=6, error=2.193\n",
      ">epoch=7, error=2.179\n",
      ">epoch=8, error=2.170\n",
      ">epoch=9, error=2.164\n",
      ">epoch=10, error=2.160\n",
      ">epoch=11, error=2.157\n",
      ">epoch=12, error=2.155\n",
      ">epoch=13, error=2.153\n",
      ">epoch=14, error=2.152\n",
      ">epoch=15, error=2.150\n",
      ">epoch=16, error=2.149\n",
      ">epoch=17, error=2.148\n",
      ">epoch=18, error=2.147\n",
      ">epoch=19, error=2.145\n",
      ">epoch=20, error=2.144\n",
      ">epoch=21, error=2.143\n",
      ">epoch=22, error=2.142\n",
      ">epoch=23, error=2.141\n",
      ">epoch=24, error=2.140\n",
      ">epoch=25, error=2.139\n",
      ">epoch=26, error=2.137\n",
      ">epoch=27, error=2.136\n",
      ">epoch=28, error=2.135\n",
      ">epoch=29, error=2.134\n",
      ">epoch=30, error=2.133\n",
      ">epoch=31, error=2.132\n",
      ">epoch=32, error=2.131\n",
      ">epoch=33, error=2.130\n",
      ">epoch=34, error=2.129\n",
      ">epoch=35, error=2.127\n",
      ">epoch=36, error=2.126\n",
      ">epoch=37, error=2.125\n",
      ">epoch=38, error=2.124\n",
      ">epoch=39, error=2.123\n",
      ">epoch=40, error=2.122\n",
      ">epoch=41, error=2.121\n",
      ">epoch=42, error=2.120\n",
      ">epoch=43, error=2.119\n",
      ">epoch=44, error=2.118\n",
      ">epoch=45, error=2.116\n",
      ">epoch=46, error=2.115\n",
      ">epoch=47, error=2.114\n",
      ">epoch=48, error=2.113\n",
      ">epoch=49, error=2.112\n",
      ">epoch=50, error=2.111\n",
      ">epoch=51, error=2.110\n",
      ">epoch=52, error=2.109\n",
      ">epoch=53, error=2.108\n",
      ">epoch=54, error=2.107\n",
      ">epoch=55, error=2.106\n",
      ">epoch=56, error=2.105\n",
      ">epoch=57, error=2.104\n",
      ">epoch=58, error=2.102\n",
      ">epoch=59, error=2.101\n",
      ">epoch=60, error=2.100\n",
      ">epoch=61, error=2.099\n",
      ">epoch=62, error=2.098\n",
      ">epoch=63, error=2.097\n",
      ">epoch=64, error=2.096\n",
      ">epoch=65, error=2.095\n",
      ">epoch=66, error=2.094\n",
      ">epoch=67, error=2.093\n",
      ">epoch=68, error=2.092\n",
      ">epoch=69, error=2.091\n",
      ">epoch=70, error=2.090\n",
      ">epoch=71, error=2.089\n",
      ">epoch=72, error=2.088\n",
      ">epoch=73, error=2.087\n",
      ">epoch=74, error=2.087\n",
      ">epoch=75, error=2.086\n",
      ">epoch=76, error=2.085\n",
      ">epoch=77, error=2.084\n",
      ">epoch=78, error=2.083\n",
      ">epoch=79, error=2.082\n",
      ">epoch=80, error=2.081\n",
      ">epoch=81, error=2.081\n",
      ">epoch=82, error=2.080\n",
      ">epoch=83, error=2.079\n",
      ">epoch=84, error=2.078\n",
      ">epoch=85, error=2.078\n",
      ">epoch=86, error=2.077\n",
      ">epoch=87, error=2.076\n",
      ">epoch=88, error=2.076\n",
      ">epoch=89, error=2.075\n",
      ">epoch=90, error=2.075\n",
      ">epoch=91, error=2.074\n",
      ">epoch=92, error=2.074\n",
      ">epoch=93, error=2.073\n",
      ">epoch=94, error=2.073\n",
      ">epoch=95, error=2.072\n",
      ">epoch=96, error=2.072\n",
      ">epoch=97, error=2.071\n",
      ">epoch=98, error=2.071\n",
      ">epoch=99, error=2.071\n",
      ">epoch=100, error=2.070\n",
      ">epoch=101, error=2.070\n",
      ">epoch=102, error=2.070\n",
      ">epoch=103, error=2.070\n",
      ">epoch=104, error=2.070\n",
      ">epoch=105, error=2.069\n",
      ">epoch=106, error=2.069\n",
      ">epoch=107, error=2.069\n",
      ">epoch=108, error=2.069\n",
      ">epoch=109, error=2.069\n",
      ">epoch=110, error=2.069\n",
      ">epoch=111, error=2.069\n",
      ">epoch=112, error=2.069\n",
      ">epoch=113, error=2.069\n",
      ">epoch=114, error=2.069\n",
      ">epoch=115, error=2.069\n",
      ">epoch=116, error=2.069\n",
      ">epoch=117, error=2.070\n",
      ">epoch=118, error=2.070\n",
      ">epoch=119, error=2.070\n",
      ">epoch=120, error=2.070\n",
      ">epoch=121, error=2.070\n",
      ">epoch=122, error=2.071\n",
      ">epoch=123, error=2.071\n",
      ">epoch=124, error=2.071\n",
      ">epoch=125, error=2.071\n",
      ">epoch=126, error=2.072\n",
      ">epoch=127, error=2.072\n",
      ">epoch=128, error=2.072\n",
      ">epoch=129, error=2.072\n",
      ">epoch=130, error=2.073\n",
      ">epoch=131, error=2.073\n",
      ">epoch=132, error=2.073\n",
      ">epoch=133, error=2.074\n",
      ">epoch=134, error=2.074\n",
      ">epoch=135, error=2.074\n",
      ">epoch=136, error=2.075\n",
      ">epoch=137, error=2.075\n",
      ">epoch=138, error=2.075\n",
      ">epoch=139, error=2.076\n",
      ">epoch=140, error=2.076\n",
      ">epoch=141, error=2.077\n",
      ">epoch=142, error=2.077\n",
      ">epoch=143, error=2.077\n",
      ">epoch=144, error=2.078\n",
      ">epoch=145, error=2.078\n",
      ">epoch=146, error=2.078\n",
      ">epoch=147, error=2.079\n",
      ">epoch=148, error=2.079\n",
      ">epoch=149, error=2.080\n",
      ">epoch=150, error=2.080\n",
      ">epoch=151, error=2.080\n",
      ">epoch=152, error=2.081\n",
      ">epoch=153, error=2.081\n",
      ">epoch=154, error=2.081\n",
      ">epoch=155, error=2.082\n",
      ">epoch=156, error=2.082\n",
      ">epoch=157, error=2.082\n",
      ">epoch=158, error=2.083\n",
      ">epoch=159, error=2.083\n",
      ">epoch=160, error=2.083\n",
      ">epoch=161, error=2.084\n",
      ">epoch=162, error=2.084\n",
      ">epoch=163, error=2.084\n",
      ">epoch=164, error=2.085\n",
      ">epoch=165, error=2.085\n",
      ">epoch=166, error=2.085\n",
      ">epoch=167, error=2.085\n",
      ">epoch=168, error=2.086\n",
      ">epoch=169, error=2.086\n",
      ">epoch=170, error=2.086\n",
      ">epoch=171, error=2.087\n",
      ">epoch=172, error=2.087\n",
      ">epoch=173, error=2.087\n",
      ">epoch=174, error=2.087\n",
      ">epoch=175, error=2.088\n",
      ">epoch=176, error=2.088\n",
      ">epoch=177, error=2.088\n",
      ">epoch=178, error=2.088\n",
      ">epoch=179, error=2.089\n",
      ">epoch=180, error=2.089\n",
      ">epoch=181, error=2.089\n",
      ">epoch=182, error=2.089\n",
      ">epoch=183, error=2.089\n",
      ">epoch=184, error=2.089\n",
      ">epoch=185, error=2.090\n",
      ">epoch=186, error=2.090\n",
      ">epoch=187, error=2.090\n",
      ">epoch=188, error=2.090\n",
      ">epoch=189, error=2.090\n",
      ">epoch=190, error=2.090\n",
      ">epoch=191, error=2.091\n",
      ">epoch=192, error=2.091\n",
      ">epoch=193, error=2.091\n",
      ">epoch=194, error=2.091\n",
      ">epoch=195, error=2.091\n",
      ">epoch=196, error=2.091\n",
      ">epoch=197, error=2.091\n",
      ">epoch=198, error=2.091\n",
      ">epoch=199, error=2.092\n",
      ">epoch=200, error=2.092\n",
      ">epoch=201, error=2.092\n",
      ">epoch=202, error=2.092\n",
      ">epoch=203, error=2.092\n",
      ">epoch=204, error=2.092\n",
      ">epoch=205, error=2.092\n",
      ">epoch=206, error=2.092\n",
      ">epoch=207, error=2.092\n",
      ">epoch=208, error=2.092\n",
      ">epoch=209, error=2.092\n",
      ">epoch=210, error=2.092\n",
      ">epoch=211, error=2.092\n",
      ">epoch=212, error=2.092\n",
      ">epoch=213, error=2.092\n",
      ">epoch=214, error=2.092\n",
      ">epoch=215, error=2.092\n",
      ">epoch=216, error=2.092\n",
      ">epoch=217, error=2.092\n",
      ">epoch=218, error=2.092\n",
      ">epoch=219, error=2.092\n",
      ">epoch=220, error=2.092\n",
      ">epoch=221, error=2.092\n",
      ">epoch=222, error=2.092\n",
      ">epoch=223, error=2.092\n",
      ">epoch=224, error=2.092\n",
      ">epoch=225, error=2.092\n",
      ">epoch=226, error=2.092\n",
      ">epoch=227, error=2.092\n",
      ">epoch=228, error=2.092\n",
      ">epoch=229, error=2.091\n",
      ">epoch=230, error=2.091\n",
      ">epoch=231, error=2.091\n",
      ">epoch=232, error=2.091\n",
      ">epoch=233, error=2.091\n",
      ">epoch=234, error=2.091\n",
      ">epoch=235, error=2.091\n",
      ">epoch=236, error=2.091\n",
      ">epoch=237, error=2.091\n",
      ">epoch=238, error=2.091\n",
      ">epoch=239, error=2.090\n",
      ">epoch=240, error=2.090\n",
      ">epoch=241, error=2.090\n",
      ">epoch=242, error=2.090\n",
      ">epoch=243, error=2.090\n",
      ">epoch=244, error=2.090\n",
      ">epoch=245, error=2.090\n",
      ">epoch=246, error=2.089\n",
      ">epoch=247, error=2.089\n",
      ">epoch=248, error=2.089\n",
      ">epoch=249, error=2.089\n",
      ">epoch=250, error=2.089\n",
      ">epoch=251, error=2.089\n",
      ">epoch=252, error=2.088\n",
      ">epoch=253, error=2.088\n",
      ">epoch=254, error=2.088\n",
      ">epoch=255, error=2.088\n",
      ">epoch=256, error=2.088\n",
      ">epoch=257, error=2.088\n",
      ">epoch=258, error=2.087\n",
      ">epoch=259, error=2.087\n",
      ">epoch=260, error=2.087\n",
      ">epoch=261, error=2.087\n",
      ">epoch=262, error=2.087\n",
      ">epoch=263, error=2.086\n",
      ">epoch=264, error=2.086\n",
      ">epoch=265, error=2.086\n",
      ">epoch=266, error=2.086\n",
      ">epoch=267, error=2.086\n",
      ">epoch=268, error=2.085\n",
      ">epoch=269, error=2.085\n",
      ">epoch=270, error=2.085\n",
      ">epoch=271, error=2.085\n",
      ">epoch=272, error=2.085\n",
      ">epoch=273, error=2.084\n",
      ">epoch=274, error=2.084\n",
      ">epoch=275, error=2.084\n",
      ">epoch=276, error=2.084\n",
      ">epoch=277, error=2.083\n",
      ">epoch=278, error=2.083\n",
      ">epoch=279, error=2.083\n",
      ">epoch=280, error=2.083\n",
      ">epoch=281, error=2.083\n",
      ">epoch=282, error=2.082\n",
      ">epoch=283, error=2.082\n",
      ">epoch=284, error=2.082\n",
      ">epoch=285, error=2.082\n",
      ">epoch=286, error=2.082\n",
      ">epoch=287, error=2.081\n",
      ">epoch=288, error=2.081\n",
      ">epoch=289, error=2.081\n",
      ">epoch=290, error=2.081\n",
      ">epoch=291, error=2.080\n",
      ">epoch=292, error=2.080\n",
      ">epoch=293, error=2.080\n",
      ">epoch=294, error=2.080\n",
      ">epoch=295, error=2.079\n",
      ">epoch=296, error=2.079\n",
      ">epoch=297, error=2.079\n",
      ">epoch=298, error=2.079\n",
      ">epoch=299, error=2.079\n",
      ">epoch=300, error=2.078\n",
      ">epoch=301, error=2.078\n",
      ">epoch=302, error=2.078\n",
      ">epoch=303, error=2.078\n",
      ">epoch=304, error=2.077\n",
      ">epoch=305, error=2.077\n",
      ">epoch=306, error=2.077\n",
      ">epoch=307, error=2.077\n",
      ">epoch=308, error=2.077\n",
      ">epoch=309, error=2.076\n",
      ">epoch=310, error=2.076\n",
      ">epoch=311, error=2.076\n",
      ">epoch=312, error=2.076\n",
      ">epoch=313, error=2.076\n",
      ">epoch=314, error=2.075\n",
      ">epoch=315, error=2.075\n",
      ">epoch=316, error=2.075\n",
      ">epoch=317, error=2.075\n",
      ">epoch=318, error=2.074\n",
      ">epoch=319, error=2.074\n",
      ">epoch=320, error=2.074\n",
      ">epoch=321, error=2.074\n",
      ">epoch=322, error=2.074\n",
      ">epoch=323, error=2.073\n",
      ">epoch=324, error=2.073\n",
      ">epoch=325, error=2.073\n",
      ">epoch=326, error=2.073\n",
      ">epoch=327, error=2.073\n",
      ">epoch=328, error=2.072\n",
      ">epoch=329, error=2.072\n",
      ">epoch=330, error=2.072\n",
      ">epoch=331, error=2.072\n",
      ">epoch=332, error=2.072\n",
      ">epoch=333, error=2.071\n",
      ">epoch=334, error=2.071\n",
      ">epoch=335, error=2.071\n",
      ">epoch=336, error=2.071\n",
      ">epoch=337, error=2.071\n",
      ">epoch=338, error=2.070\n",
      ">epoch=339, error=2.070\n",
      ">epoch=340, error=2.070\n",
      ">epoch=341, error=2.070\n",
      ">epoch=342, error=2.070\n",
      ">epoch=343, error=2.070\n",
      ">epoch=344, error=2.069\n",
      ">epoch=345, error=2.069\n",
      ">epoch=346, error=2.069\n",
      ">epoch=347, error=2.069\n",
      ">epoch=348, error=2.069\n",
      ">epoch=349, error=2.068\n",
      ">epoch=350, error=2.068\n",
      ">epoch=351, error=2.068\n",
      ">epoch=352, error=2.068\n",
      ">epoch=353, error=2.068\n",
      ">epoch=354, error=2.068\n",
      ">epoch=355, error=2.067\n",
      ">epoch=356, error=2.067\n",
      ">epoch=357, error=2.067\n",
      ">epoch=358, error=2.067\n",
      ">epoch=359, error=2.067\n",
      ">epoch=360, error=2.066\n",
      ">epoch=361, error=2.066\n",
      ">epoch=362, error=2.066\n",
      ">epoch=363, error=2.066\n",
      ">epoch=364, error=2.066\n",
      ">epoch=365, error=2.065\n",
      ">epoch=366, error=2.065\n",
      ">epoch=367, error=2.065\n",
      ">epoch=368, error=2.065\n",
      ">epoch=369, error=2.065\n",
      ">epoch=370, error=2.065\n",
      ">epoch=371, error=2.064\n",
      ">epoch=372, error=2.064\n",
      ">epoch=373, error=2.064\n",
      ">epoch=374, error=2.064\n",
      ">epoch=375, error=2.064\n",
      ">epoch=376, error=2.063\n",
      ">epoch=377, error=2.063\n",
      ">epoch=378, error=2.063\n",
      ">epoch=379, error=2.063\n",
      ">epoch=380, error=2.063\n",
      ">epoch=381, error=2.062\n",
      ">epoch=382, error=2.062\n",
      ">epoch=383, error=2.062\n",
      ">epoch=384, error=2.062\n",
      ">epoch=385, error=2.062\n",
      ">epoch=386, error=2.061\n",
      ">epoch=387, error=2.061\n",
      ">epoch=388, error=2.061\n",
      ">epoch=389, error=2.061\n",
      ">epoch=390, error=2.061\n",
      ">epoch=391, error=2.060\n",
      ">epoch=392, error=2.060\n",
      ">epoch=393, error=2.060\n",
      ">epoch=394, error=2.060\n",
      ">epoch=395, error=2.059\n",
      ">epoch=396, error=2.059\n",
      ">epoch=397, error=2.059\n",
      ">epoch=398, error=2.059\n",
      ">epoch=399, error=2.058\n",
      ">epoch=400, error=2.058\n",
      ">epoch=401, error=2.058\n",
      ">epoch=402, error=2.058\n",
      ">epoch=403, error=2.057\n",
      ">epoch=404, error=2.057\n",
      ">epoch=405, error=2.057\n",
      ">epoch=406, error=2.057\n",
      ">epoch=407, error=2.056\n",
      ">epoch=408, error=2.056\n",
      ">epoch=409, error=2.056\n",
      ">epoch=410, error=2.056\n",
      ">epoch=411, error=2.055\n",
      ">epoch=412, error=2.055\n",
      ">epoch=413, error=2.055\n",
      ">epoch=414, error=2.054\n",
      ">epoch=415, error=2.054\n",
      ">epoch=416, error=2.054\n",
      ">epoch=417, error=2.053\n",
      ">epoch=418, error=2.053\n",
      ">epoch=419, error=2.053\n",
      ">epoch=420, error=2.052\n",
      ">epoch=421, error=2.052\n",
      ">epoch=422, error=2.052\n",
      ">epoch=423, error=2.051\n",
      ">epoch=424, error=2.051\n",
      ">epoch=425, error=2.051\n",
      ">epoch=426, error=2.050\n",
      ">epoch=427, error=2.050\n",
      ">epoch=428, error=2.050\n",
      ">epoch=429, error=2.049\n",
      ">epoch=430, error=2.049\n",
      ">epoch=431, error=2.048\n",
      ">epoch=432, error=2.048\n",
      ">epoch=433, error=2.048\n",
      ">epoch=434, error=2.047\n",
      ">epoch=435, error=2.047\n",
      ">epoch=436, error=2.046\n",
      ">epoch=437, error=2.046\n",
      ">epoch=438, error=2.045\n",
      ">epoch=439, error=2.045\n",
      ">epoch=440, error=2.045\n",
      ">epoch=441, error=2.044\n",
      ">epoch=442, error=2.044\n",
      ">epoch=443, error=2.043\n",
      ">epoch=444, error=2.043\n",
      ">epoch=445, error=2.042\n",
      ">epoch=446, error=2.042\n",
      ">epoch=447, error=2.041\n",
      ">epoch=448, error=2.041\n",
      ">epoch=449, error=2.040\n",
      ">epoch=450, error=2.040\n",
      ">epoch=451, error=2.039\n",
      ">epoch=452, error=2.039\n",
      ">epoch=453, error=2.038\n",
      ">epoch=454, error=2.038\n",
      ">epoch=455, error=2.037\n",
      ">epoch=456, error=2.037\n",
      ">epoch=457, error=2.036\n",
      ">epoch=458, error=2.035\n",
      ">epoch=459, error=2.035\n",
      ">epoch=460, error=2.034\n",
      ">epoch=461, error=2.034\n",
      ">epoch=462, error=2.033\n",
      ">epoch=463, error=2.032\n",
      ">epoch=464, error=2.032\n",
      ">epoch=465, error=2.031\n",
      ">epoch=466, error=2.031\n",
      ">epoch=467, error=2.030\n",
      ">epoch=468, error=2.029\n",
      ">epoch=469, error=2.029\n",
      ">epoch=470, error=2.028\n",
      ">epoch=471, error=2.028\n",
      ">epoch=472, error=2.027\n",
      ">epoch=473, error=2.026\n",
      ">epoch=474, error=2.026\n",
      ">epoch=475, error=2.025\n",
      ">epoch=476, error=2.024\n",
      ">epoch=477, error=2.024\n",
      ">epoch=478, error=2.023\n",
      ">epoch=479, error=2.022\n",
      ">epoch=480, error=2.022\n",
      ">epoch=481, error=2.021\n",
      ">epoch=482, error=2.020\n",
      ">epoch=483, error=2.019\n",
      ">epoch=484, error=2.019\n",
      ">epoch=485, error=2.018\n",
      ">epoch=486, error=2.017\n",
      ">epoch=487, error=2.017\n",
      ">epoch=488, error=2.016\n",
      ">epoch=489, error=2.015\n",
      ">epoch=490, error=2.015\n",
      ">epoch=491, error=2.014\n",
      ">epoch=492, error=2.013\n",
      ">epoch=493, error=2.012\n",
      ">epoch=494, error=2.012\n",
      ">epoch=495, error=2.011\n",
      ">epoch=496, error=2.010\n",
      ">epoch=497, error=2.009\n",
      ">epoch=498, error=2.009\n",
      ">epoch=499, error=2.008\n",
      ">epoch=500, error=2.007\n",
      ">epoch=501, error=2.006\n",
      ">epoch=502, error=2.006\n",
      ">epoch=503, error=2.005\n",
      ">epoch=504, error=2.004\n",
      ">epoch=505, error=2.003\n",
      ">epoch=506, error=2.003\n",
      ">epoch=507, error=2.002\n",
      ">epoch=508, error=2.001\n",
      ">epoch=509, error=2.001\n",
      ">epoch=510, error=2.000\n",
      ">epoch=511, error=1.999\n",
      ">epoch=512, error=1.998\n",
      ">epoch=513, error=1.998\n",
      ">epoch=514, error=1.997\n",
      ">epoch=515, error=1.996\n",
      ">epoch=516, error=1.995\n",
      ">epoch=517, error=1.995\n",
      ">epoch=518, error=1.994\n",
      ">epoch=519, error=1.993\n",
      ">epoch=520, error=1.992\n",
      ">epoch=521, error=1.992\n",
      ">epoch=522, error=1.991\n",
      ">epoch=523, error=1.990\n",
      ">epoch=524, error=1.989\n",
      ">epoch=525, error=1.989\n",
      ">epoch=526, error=1.988\n",
      ">epoch=527, error=1.987\n",
      ">epoch=528, error=1.986\n",
      ">epoch=529, error=1.986\n",
      ">epoch=530, error=1.985\n",
      ">epoch=531, error=1.984\n",
      ">epoch=532, error=1.984\n",
      ">epoch=533, error=1.983\n",
      ">epoch=534, error=1.982\n",
      ">epoch=535, error=1.981\n",
      ">epoch=536, error=1.981\n",
      ">epoch=537, error=1.980\n",
      ">epoch=538, error=1.979\n",
      ">epoch=539, error=1.979\n",
      ">epoch=540, error=1.978\n",
      ">epoch=541, error=1.977\n",
      ">epoch=542, error=1.976\n",
      ">epoch=543, error=1.976\n",
      ">epoch=544, error=1.975\n",
      ">epoch=545, error=1.974\n",
      ">epoch=546, error=1.974\n",
      ">epoch=547, error=1.973\n",
      ">epoch=548, error=1.972\n",
      ">epoch=549, error=1.972\n",
      ">epoch=550, error=1.971\n",
      ">epoch=551, error=1.970\n",
      ">epoch=552, error=1.970\n",
      ">epoch=553, error=1.969\n",
      ">epoch=554, error=1.968\n",
      ">epoch=555, error=1.968\n",
      ">epoch=556, error=1.967\n",
      ">epoch=557, error=1.966\n",
      ">epoch=558, error=1.966\n",
      ">epoch=559, error=1.965\n",
      ">epoch=560, error=1.964\n",
      ">epoch=561, error=1.964\n",
      ">epoch=562, error=1.963\n",
      ">epoch=563, error=1.962\n",
      ">epoch=564, error=1.962\n",
      ">epoch=565, error=1.961\n",
      ">epoch=566, error=1.960\n",
      ">epoch=567, error=1.960\n",
      ">epoch=568, error=1.959\n",
      ">epoch=569, error=1.958\n",
      ">epoch=570, error=1.958\n",
      ">epoch=571, error=1.957\n",
      ">epoch=572, error=1.956\n",
      ">epoch=573, error=1.956\n",
      ">epoch=574, error=1.955\n",
      ">epoch=575, error=1.954\n",
      ">epoch=576, error=1.954\n",
      ">epoch=577, error=1.953\n",
      ">epoch=578, error=1.952\n",
      ">epoch=579, error=1.952\n",
      ">epoch=580, error=1.951\n",
      ">epoch=581, error=1.951\n",
      ">epoch=582, error=1.950\n",
      ">epoch=583, error=1.949\n",
      ">epoch=584, error=1.949\n",
      ">epoch=585, error=1.948\n",
      ">epoch=586, error=1.947\n",
      ">epoch=587, error=1.947\n",
      ">epoch=588, error=1.946\n",
      ">epoch=589, error=1.945\n",
      ">epoch=590, error=1.945\n",
      ">epoch=591, error=1.944\n",
      ">epoch=592, error=1.943\n",
      ">epoch=593, error=1.942\n",
      ">epoch=594, error=1.942\n",
      ">epoch=595, error=1.941\n",
      ">epoch=596, error=1.940\n",
      ">epoch=597, error=1.940\n",
      ">epoch=598, error=1.939\n",
      ">epoch=599, error=1.938\n",
      ">epoch=600, error=1.937\n",
      ">epoch=601, error=1.937\n",
      ">epoch=602, error=1.936\n",
      ">epoch=603, error=1.935\n",
      ">epoch=604, error=1.934\n",
      ">epoch=605, error=1.934\n",
      ">epoch=606, error=1.933\n",
      ">epoch=607, error=1.932\n",
      ">epoch=608, error=1.931\n",
      ">epoch=609, error=1.931\n",
      ">epoch=610, error=1.930\n",
      ">epoch=611, error=1.929\n",
      ">epoch=612, error=1.928\n",
      ">epoch=613, error=1.927\n",
      ">epoch=614, error=1.926\n",
      ">epoch=615, error=1.926\n",
      ">epoch=616, error=1.925\n",
      ">epoch=617, error=1.924\n",
      ">epoch=618, error=1.923\n",
      ">epoch=619, error=1.922\n",
      ">epoch=620, error=1.921\n",
      ">epoch=621, error=1.920\n",
      ">epoch=622, error=1.919\n",
      ">epoch=623, error=1.918\n",
      ">epoch=624, error=1.917\n",
      ">epoch=625, error=1.916\n",
      ">epoch=626, error=1.915\n",
      ">epoch=627, error=1.914\n",
      ">epoch=628, error=1.913\n",
      ">epoch=629, error=1.912\n",
      ">epoch=630, error=1.911\n",
      ">epoch=631, error=1.910\n",
      ">epoch=632, error=1.909\n",
      ">epoch=633, error=1.908\n",
      ">epoch=634, error=1.907\n",
      ">epoch=635, error=1.905\n",
      ">epoch=636, error=1.904\n",
      ">epoch=637, error=1.903\n",
      ">epoch=638, error=1.902\n",
      ">epoch=639, error=1.901\n",
      ">epoch=640, error=1.899\n",
      ">epoch=641, error=1.898\n",
      ">epoch=642, error=1.897\n",
      ">epoch=643, error=1.895\n",
      ">epoch=644, error=1.894\n",
      ">epoch=645, error=1.893\n",
      ">epoch=646, error=1.891\n",
      ">epoch=647, error=1.890\n",
      ">epoch=648, error=1.889\n",
      ">epoch=649, error=1.887\n",
      ">epoch=650, error=1.886\n",
      ">epoch=651, error=1.884\n",
      ">epoch=652, error=1.883\n",
      ">epoch=653, error=1.881\n",
      ">epoch=654, error=1.879\n",
      ">epoch=655, error=1.878\n",
      ">epoch=656, error=1.876\n",
      ">epoch=657, error=1.875\n",
      ">epoch=658, error=1.873\n",
      ">epoch=659, error=1.871\n",
      ">epoch=660, error=1.869\n",
      ">epoch=661, error=1.868\n",
      ">epoch=662, error=1.866\n",
      ">epoch=663, error=1.864\n",
      ">epoch=664, error=1.862\n",
      ">epoch=665, error=1.860\n",
      ">epoch=666, error=1.858\n",
      ">epoch=667, error=1.856\n",
      ">epoch=668, error=1.855\n",
      ">epoch=669, error=1.853\n",
      ">epoch=670, error=1.851\n",
      ">epoch=671, error=1.849\n",
      ">epoch=672, error=1.846\n",
      ">epoch=673, error=1.844\n",
      ">epoch=674, error=1.842\n",
      ">epoch=675, error=1.840\n",
      ">epoch=676, error=1.838\n",
      ">epoch=677, error=1.836\n",
      ">epoch=678, error=1.833\n",
      ">epoch=679, error=1.831\n",
      ">epoch=680, error=1.829\n",
      ">epoch=681, error=1.827\n",
      ">epoch=682, error=1.824\n",
      ">epoch=683, error=1.822\n",
      ">epoch=684, error=1.819\n",
      ">epoch=685, error=1.817\n",
      ">epoch=686, error=1.814\n",
      ">epoch=687, error=1.812\n",
      ">epoch=688, error=1.809\n",
      ">epoch=689, error=1.807\n",
      ">epoch=690, error=1.804\n",
      ">epoch=691, error=1.801\n",
      ">epoch=692, error=1.799\n",
      ">epoch=693, error=1.796\n",
      ">epoch=694, error=1.793\n",
      ">epoch=695, error=1.790\n",
      ">epoch=696, error=1.787\n",
      ">epoch=697, error=1.784\n",
      ">epoch=698, error=1.782\n",
      ">epoch=699, error=1.779\n",
      ">epoch=700, error=1.776\n",
      ">epoch=701, error=1.772\n",
      ">epoch=702, error=1.769\n",
      ">epoch=703, error=1.766\n",
      ">epoch=704, error=1.763\n",
      ">epoch=705, error=1.760\n",
      ">epoch=706, error=1.756\n",
      ">epoch=707, error=1.753\n",
      ">epoch=708, error=1.750\n",
      ">epoch=709, error=1.746\n",
      ">epoch=710, error=1.743\n",
      ">epoch=711, error=1.739\n",
      ">epoch=712, error=1.736\n",
      ">epoch=713, error=1.732\n",
      ">epoch=714, error=1.728\n",
      ">epoch=715, error=1.725\n",
      ">epoch=716, error=1.721\n",
      ">epoch=717, error=1.717\n",
      ">epoch=718, error=1.713\n",
      ">epoch=719, error=1.709\n",
      ">epoch=720, error=1.705\n",
      ">epoch=721, error=1.701\n",
      ">epoch=722, error=1.697\n",
      ">epoch=723, error=1.692\n",
      ">epoch=724, error=1.688\n",
      ">epoch=725, error=1.684\n",
      ">epoch=726, error=1.679\n",
      ">epoch=727, error=1.675\n",
      ">epoch=728, error=1.670\n",
      ">epoch=729, error=1.666\n",
      ">epoch=730, error=1.661\n",
      ">epoch=731, error=1.656\n",
      ">epoch=732, error=1.651\n",
      ">epoch=733, error=1.646\n",
      ">epoch=734, error=1.641\n",
      ">epoch=735, error=1.636\n",
      ">epoch=736, error=1.631\n",
      ">epoch=737, error=1.626\n",
      ">epoch=738, error=1.620\n",
      ">epoch=739, error=1.615\n",
      ">epoch=740, error=1.609\n",
      ">epoch=741, error=1.604\n",
      ">epoch=742, error=1.598\n",
      ">epoch=743, error=1.592\n",
      ">epoch=744, error=1.586\n",
      ">epoch=745, error=1.580\n",
      ">epoch=746, error=1.574\n",
      ">epoch=747, error=1.568\n",
      ">epoch=748, error=1.561\n",
      ">epoch=749, error=1.555\n",
      ">epoch=750, error=1.549\n",
      ">epoch=751, error=1.542\n",
      ">epoch=752, error=1.535\n",
      ">epoch=753, error=1.528\n",
      ">epoch=754, error=1.521\n",
      ">epoch=755, error=1.514\n",
      ">epoch=756, error=1.507\n",
      ">epoch=757, error=1.500\n",
      ">epoch=758, error=1.493\n",
      ">epoch=759, error=1.485\n",
      ">epoch=760, error=1.477\n",
      ">epoch=761, error=1.470\n",
      ">epoch=762, error=1.462\n",
      ">epoch=763, error=1.454\n",
      ">epoch=764, error=1.446\n",
      ">epoch=765, error=1.438\n",
      ">epoch=766, error=1.429\n",
      ">epoch=767, error=1.421\n",
      ">epoch=768, error=1.413\n",
      ">epoch=769, error=1.404\n",
      ">epoch=770, error=1.395\n",
      ">epoch=771, error=1.386\n",
      ">epoch=772, error=1.377\n",
      ">epoch=773, error=1.368\n",
      ">epoch=774, error=1.359\n",
      ">epoch=775, error=1.350\n",
      ">epoch=776, error=1.340\n",
      ">epoch=777, error=1.331\n",
      ">epoch=778, error=1.321\n",
      ">epoch=779, error=1.312\n",
      ">epoch=780, error=1.302\n",
      ">epoch=781, error=1.292\n",
      ">epoch=782, error=1.282\n",
      ">epoch=783, error=1.272\n",
      ">epoch=784, error=1.262\n",
      ">epoch=785, error=1.252\n",
      ">epoch=786, error=1.242\n",
      ">epoch=787, error=1.231\n",
      ">epoch=788, error=1.221\n",
      ">epoch=789, error=1.210\n",
      ">epoch=790, error=1.200\n",
      ">epoch=791, error=1.189\n",
      ">epoch=792, error=1.179\n",
      ">epoch=793, error=1.168\n",
      ">epoch=794, error=1.157\n",
      ">epoch=795, error=1.146\n",
      ">epoch=796, error=1.136\n",
      ">epoch=797, error=1.125\n",
      ">epoch=798, error=1.114\n",
      ">epoch=799, error=1.103\n",
      ">epoch=800, error=1.092\n",
      ">epoch=801, error=1.082\n",
      ">epoch=802, error=1.071\n",
      ">epoch=803, error=1.060\n",
      ">epoch=804, error=1.049\n",
      ">epoch=805, error=1.038\n",
      ">epoch=806, error=1.028\n",
      ">epoch=807, error=1.017\n",
      ">epoch=808, error=1.006\n",
      ">epoch=809, error=0.996\n",
      ">epoch=810, error=0.985\n",
      ">epoch=811, error=0.975\n",
      ">epoch=812, error=0.964\n",
      ">epoch=813, error=0.954\n",
      ">epoch=814, error=0.943\n",
      ">epoch=815, error=0.933\n",
      ">epoch=816, error=0.923\n",
      ">epoch=817, error=0.912\n",
      ">epoch=818, error=0.902\n",
      ">epoch=819, error=0.892\n",
      ">epoch=820, error=0.882\n",
      ">epoch=821, error=0.873\n",
      ">epoch=822, error=0.863\n",
      ">epoch=823, error=0.853\n",
      ">epoch=824, error=0.844\n",
      ">epoch=825, error=0.834\n",
      ">epoch=826, error=0.825\n",
      ">epoch=827, error=0.815\n",
      ">epoch=828, error=0.806\n",
      ">epoch=829, error=0.797\n",
      ">epoch=830, error=0.788\n",
      ">epoch=831, error=0.779\n",
      ">epoch=832, error=0.770\n",
      ">epoch=833, error=0.762\n",
      ">epoch=834, error=0.753\n",
      ">epoch=835, error=0.745\n",
      ">epoch=836, error=0.736\n",
      ">epoch=837, error=0.728\n",
      ">epoch=838, error=0.720\n",
      ">epoch=839, error=0.712\n",
      ">epoch=840, error=0.704\n",
      ">epoch=841, error=0.696\n",
      ">epoch=842, error=0.689\n",
      ">epoch=843, error=0.681\n",
      ">epoch=844, error=0.673\n",
      ">epoch=845, error=0.666\n",
      ">epoch=846, error=0.659\n",
      ">epoch=847, error=0.652\n",
      ">epoch=848, error=0.644\n",
      ">epoch=849, error=0.637\n",
      ">epoch=850, error=0.631\n",
      ">epoch=851, error=0.624\n",
      ">epoch=852, error=0.617\n",
      ">epoch=853, error=0.610\n",
      ">epoch=854, error=0.604\n",
      ">epoch=855, error=0.598\n",
      ">epoch=856, error=0.591\n",
      ">epoch=857, error=0.585\n",
      ">epoch=858, error=0.579\n",
      ">epoch=859, error=0.573\n",
      ">epoch=860, error=0.567\n",
      ">epoch=861, error=0.561\n",
      ">epoch=862, error=0.555\n",
      ">epoch=863, error=0.549\n",
      ">epoch=864, error=0.544\n",
      ">epoch=865, error=0.538\n",
      ">epoch=866, error=0.533\n",
      ">epoch=867, error=0.527\n",
      ">epoch=868, error=0.522\n",
      ">epoch=869, error=0.517\n",
      ">epoch=870, error=0.512\n",
      ">epoch=871, error=0.507\n",
      ">epoch=872, error=0.502\n",
      ">epoch=873, error=0.497\n",
      ">epoch=874, error=0.492\n",
      ">epoch=875, error=0.487\n",
      ">epoch=876, error=0.483\n",
      ">epoch=877, error=0.478\n",
      ">epoch=878, error=0.473\n",
      ">epoch=879, error=0.469\n",
      ">epoch=880, error=0.464\n",
      ">epoch=881, error=0.460\n",
      ">epoch=882, error=0.456\n",
      ">epoch=883, error=0.451\n",
      ">epoch=884, error=0.447\n",
      ">epoch=885, error=0.443\n",
      ">epoch=886, error=0.439\n",
      ">epoch=887, error=0.435\n",
      ">epoch=888, error=0.431\n",
      ">epoch=889, error=0.427\n",
      ">epoch=890, error=0.423\n",
      ">epoch=891, error=0.419\n",
      ">epoch=892, error=0.416\n",
      ">epoch=893, error=0.412\n",
      ">epoch=894, error=0.408\n",
      ">epoch=895, error=0.405\n",
      ">epoch=896, error=0.401\n",
      ">epoch=897, error=0.398\n",
      ">epoch=898, error=0.394\n",
      ">epoch=899, error=0.391\n",
      ">epoch=900, error=0.388\n",
      ">epoch=901, error=0.384\n",
      ">epoch=902, error=0.381\n",
      ">epoch=903, error=0.378\n",
      ">epoch=904, error=0.375\n",
      ">epoch=905, error=0.371\n",
      ">epoch=906, error=0.368\n",
      ">epoch=907, error=0.365\n",
      ">epoch=908, error=0.362\n",
      ">epoch=909, error=0.359\n",
      ">epoch=910, error=0.356\n",
      ">epoch=911, error=0.354\n",
      ">epoch=912, error=0.351\n",
      ">epoch=913, error=0.348\n",
      ">epoch=914, error=0.345\n",
      ">epoch=915, error=0.342\n",
      ">epoch=916, error=0.340\n",
      ">epoch=917, error=0.337\n",
      ">epoch=918, error=0.334\n",
      ">epoch=919, error=0.332\n",
      ">epoch=920, error=0.329\n",
      ">epoch=921, error=0.327\n",
      ">epoch=922, error=0.324\n",
      ">epoch=923, error=0.322\n",
      ">epoch=924, error=0.319\n",
      ">epoch=925, error=0.317\n",
      ">epoch=926, error=0.314\n",
      ">epoch=927, error=0.312\n",
      ">epoch=928, error=0.310\n",
      ">epoch=929, error=0.307\n",
      ">epoch=930, error=0.305\n",
      ">epoch=931, error=0.303\n",
      ">epoch=932, error=0.300\n",
      ">epoch=933, error=0.298\n",
      ">epoch=934, error=0.296\n",
      ">epoch=935, error=0.294\n",
      ">epoch=936, error=0.292\n",
      ">epoch=937, error=0.290\n",
      ">epoch=938, error=0.288\n",
      ">epoch=939, error=0.286\n",
      ">epoch=940, error=0.284\n",
      ">epoch=941, error=0.282\n",
      ">epoch=942, error=0.280\n",
      ">epoch=943, error=0.278\n",
      ">epoch=944, error=0.276\n",
      ">epoch=945, error=0.274\n",
      ">epoch=946, error=0.272\n",
      ">epoch=947, error=0.270\n",
      ">epoch=948, error=0.268\n",
      ">epoch=949, error=0.266\n",
      ">epoch=950, error=0.265\n",
      ">epoch=951, error=0.263\n",
      ">epoch=952, error=0.261\n",
      ">epoch=953, error=0.259\n",
      ">epoch=954, error=0.258\n",
      ">epoch=955, error=0.256\n",
      ">epoch=956, error=0.254\n",
      ">epoch=957, error=0.253\n",
      ">epoch=958, error=0.251\n",
      ">epoch=959, error=0.249\n",
      ">epoch=960, error=0.248\n",
      ">epoch=961, error=0.246\n",
      ">epoch=962, error=0.244\n",
      ">epoch=963, error=0.243\n",
      ">epoch=964, error=0.241\n",
      ">epoch=965, error=0.240\n",
      ">epoch=966, error=0.238\n",
      ">epoch=967, error=0.237\n",
      ">epoch=968, error=0.235\n",
      ">epoch=969, error=0.234\n",
      ">epoch=970, error=0.232\n",
      ">epoch=971, error=0.231\n",
      ">epoch=972, error=0.230\n",
      ">epoch=973, error=0.228\n",
      ">epoch=974, error=0.227\n",
      ">epoch=975, error=0.225\n",
      ">epoch=976, error=0.224\n",
      ">epoch=977, error=0.223\n",
      ">epoch=978, error=0.221\n",
      ">epoch=979, error=0.220\n",
      ">epoch=980, error=0.219\n",
      ">epoch=981, error=0.217\n",
      ">epoch=982, error=0.216\n",
      ">epoch=983, error=0.215\n",
      ">epoch=984, error=0.214\n",
      ">epoch=985, error=0.212\n",
      ">epoch=986, error=0.211\n",
      ">epoch=987, error=0.210\n",
      ">epoch=988, error=0.209\n",
      ">epoch=989, error=0.207\n",
      ">epoch=990, error=0.206\n",
      ">epoch=991, error=0.205\n",
      ">epoch=992, error=0.204\n",
      ">epoch=993, error=0.203\n",
      ">epoch=994, error=0.202\n",
      ">epoch=995, error=0.200\n",
      ">epoch=996, error=0.199\n",
      ">epoch=997, error=0.198\n",
      ">epoch=998, error=0.197\n",
      ">epoch=999, error=0.196\n",
      "Expected=0, Predicted=0\n",
      "Expected=1, Predicted=1\n",
      "Expected=1, Predicted=1\n",
      "Expected=0, Predicted=0\n"
     ]
    }
   ],
   "source": [
    "from math import exp\n",
    "from random import random, seed\n",
    "\n",
    "# Initialize seed\n",
    "seed(1)\n",
    "\n",
    "# XOR dataset\n",
    "dataset = [\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0]\n",
    "]\n",
    "\n",
    "# Activation function\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + exp(-x))\n",
    "\n",
    "# Derivative of sigmoid\n",
    "def sigmoid_derivative(output):\n",
    "    return output * (1.0 - output)\n",
    "\n",
    "# Initialize the neural network\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "    network = []\n",
    "    hidden_layer = [{'weights': [random() for _ in range(n_inputs + 1)]} for _ in range(n_hidden)]\n",
    "    network.append(hidden_layer)\n",
    "    output_layer = [{'weights': [random() for _ in range(n_hidden + 1)]} for _ in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    return network\n",
    "\n",
    "# Forward propagate input to a network output\n",
    "def forward_propagate(network, row):\n",
    "    inputs = row\n",
    "    for layer in network:\n",
    "        new_inputs = []\n",
    "        for neuron in layer:\n",
    "            activation = neuron['weights'][-1]  # bias\n",
    "            for i in range(len(inputs)):\n",
    "                activation += neuron['weights'][i] * inputs[i]\n",
    "            neuron['output'] = sigmoid(activation)\n",
    "            new_inputs.append(neuron['output'])\n",
    "        inputs = new_inputs\n",
    "    return inputs\n",
    "\n",
    "# Backward propagate the error\n",
    "def backward_propagate_error(network, expected):\n",
    "    for i in reversed(range(len(network))):\n",
    "        layer = network[i]\n",
    "        errors = []\n",
    "\n",
    "        if i == len(network) - 1:\n",
    "            # Output layer\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                errors.append(expected[j] - neuron['output'])\n",
    "        else:\n",
    "            # Hidden layer\n",
    "            for j in range(len(layer)):\n",
    "                error = 0.0\n",
    "                for neuron in network[i + 1]:\n",
    "                    error += neuron['weights'][j] * neuron['delta']\n",
    "                errors.append(error)\n",
    "\n",
    "        for j in range(len(layer)):\n",
    "            neuron = layer[j]\n",
    "            neuron['delta'] = errors[j] * sigmoid_derivative(neuron['output'])\n",
    "\n",
    "# Update network weights with error\n",
    "def update_weights(network, row, l_rate):\n",
    "    for i in range(len(network)):\n",
    "        inputs = row[:-1] if i == 0 else [neuron['output'] for neuron in network[i - 1]]\n",
    "        for neuron in network[i]:\n",
    "            for j in range(len(inputs)):\n",
    "                neuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
    "            neuron['weights'][-1] += l_rate * neuron['delta']  # bias\n",
    "\n",
    "# Train the network\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            outputs = forward_propagate(network, row)\n",
    "            expected = [0 for _ in range(n_outputs)]\n",
    "            expected[row[-1]] = 1  # One-hot encoding\n",
    "            sum_error += sum([(expected[i] - outputs[i]) ** 2 for i in range(len(expected))])\n",
    "            backward_propagate_error(network, expected)\n",
    "            update_weights(network, row, l_rate)\n",
    "        print(f'>epoch={epoch}, error={sum_error:.3f}')\n",
    "\n",
    "# Predict\n",
    "def predict(network, row):\n",
    "    outputs = forward_propagate(network, row)\n",
    "    return outputs.index(max(outputs))\n",
    "\n",
    "# Main\n",
    "n_inputs = 2\n",
    "n_outputs = 2  # Using one-hot output\n",
    "network = initialize_network(n_inputs, 2, n_outputs)\n",
    "train_network(network, dataset, l_rate=0.5, n_epoch=1000, n_outputs=n_outputs)\n",
    "\n",
    "# Test\n",
    "for row in dataset:\n",
    "    prediction = predict(network, row)\n",
    "    print(f'Expected={row[-1]}, Predicted={prediction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d2b050-b74a-4c2f-bd9d-60c079227eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using CSV file \n",
    "# first neural network\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load the dataset\n",
    "dataset = loadtxt('C:/Users/Admin/Desktop/pima-indians-diabetes.data.csv', delimiter=',')\n",
    "\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:, 0:8]\n",
    "y = dataset[:, 8]\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_shape=(8,), activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=150, batch_size=10)\n",
    "\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print(\"Accuracy: %.2f\" % (accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8b18ee-a48e-4b95-a2ec-b1df74709ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -439494.1562\n",
      "Epoch 2/10\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -11965811.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -51959912.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -128118848.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -247744656.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -416189472.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -648464768.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -943885440.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -1315856256.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m2100/2100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -1767922432.0000\n",
      "\u001b[1m657/657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: -1353314048.0000\n",
      "Accuracy: 0.00\n"
     ]
    }
   ],
   "source": [
    "#Binary Classification using a Feedforward Neural Network (MLP) in Keras on Wine Quality Data\n",
    "# Multiclass dataset\n",
    "\n",
    "# First neural network\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load the dataset\n",
    "dataset = loadtxt(r'C:/Users/Pradnya/Downloads/wine_data.csv', delimiter=',', skiprows=1)\n",
    "\n",
    "\n",
    "# Split into input (X) and output (y) variables\n",
    "X = dataset[:, 0:11]\n",
    "y = dataset[:, 11]\n",
    "\n",
    "# Define the Keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_shape=(11,), activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the Keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the Keras model on the dataset\n",
    "model.fit(X, y, epochs=10, batch_size=10)\n",
    "\n",
    "# Evaluate the Keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "403b129a-408e-4350-9622-17772d79fabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Forward Only): 22.22\n"
     ]
    }
   ],
   "source": [
    "# MLP Forward Propagation using wine\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load and preprocess data\n",
    "x, y = load_wine(return_X_y=True)\n",
    "x = MinMaxScaler().fit_transform(x)\n",
    "y = y.reshape(-1, 1)\n",
    "y_encoded = OneHotEncoder(sparse_output=False).fit_transform(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.1, random_state=42)\n",
    "\n",
    "# Initialize weights\n",
    "input_size = x_train.shape[1]\n",
    "hidden_size = 10\n",
    "output_size = y_train.shape[1]\n",
    "\n",
    "np.random.seed(42)\n",
    "W1 = np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros((1, output_size))\n",
    "\n",
    "# Activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Forward propagation\n",
    "def forward(x):\n",
    "    z1 = np.dot(x, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    return a2\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_probs = forward(x_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"Accuracy (Forward Only): %.2f\" % (accuracy_score(y_true, y_pred) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a679d0-1dbd-47e2-91af-8945dcee207a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
