{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da4e8ef-c0db-4059-b642-c098292139bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR Predictions using RBFN:\n",
      "Input: [0 0] => Predicted: 0 (Raw: 0.0000)\n",
      "Input: [0 1] => Predicted: 1 (Raw: 1.0000)\n",
      "Input: [1 0] => Predicted: 1 (Raw: 1.0000)\n",
      "Input: [1 1] => Predicted: 0 (Raw: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Gaussian RBF function\n",
    "def gaussian_rbf(x, center, sigma):\n",
    "    return np.exp(-np.linalg.norm(x - center) ** 2 / (2 * sigma ** 2))\n",
    "\n",
    "# RBFN class\n",
    "class RBFN:\n",
    "    def __init__(self, input_dim, num_centers, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.num_centers = num_centers\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # Randomly select centers from the training dataset\n",
    "        self.centers = [np.random.rand(input_dim) for _ in range(num_centers)]\n",
    "        self.sigmas = [1.0 for _ in range(num_centers)]     # Set sigma to 1 for simplicity\n",
    "        self.weights = np.random.randn(self.num_centers, output_dim)\n",
    "\n",
    "    def _basis_function(self, data_point):\n",
    "        return np.array([gaussian_rbf(data_point, c, s) for c, s in zip(self.centers, self.sigmas)])\n",
    "\n",
    "    def _calculate_interpolation_matrix(self, X):\n",
    "        G = np.zeros((X.shape[0], self.num_centers))\n",
    "        for i, data_point in enumerate(X):\n",
    "            G[i, :] = self._basis_function(data_point)\n",
    "        return G\n",
    "\n",
    "    def train(self, X, Y):\n",
    "        # Choose training data as centers\n",
    "        self.centers = X.copy()\n",
    "        self.sigmas = [1.0 for _ in range(self.num_centers)]\n",
    "        G = self._calculate_interpolation_matrix(X)\n",
    "        # Least squares solution\n",
    "        self.weights = np.dot(np.linalg.pinv(G), Y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        G = self._calculate_interpolation_matrix(X)\n",
    "        predictions = np.dot(G, self.weights)\n",
    "        return predictions\n",
    "\n",
    "# XOR dataset\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# Create and train RBFN\n",
    "model = RBFN(input_dim=2, num_centers=4, output_dim=1)\n",
    "model.train(X, Y)\n",
    "\n",
    "# Predict\n",
    "print(\"XOR Predictions using RBFN:\")\n",
    "for x in X:\n",
    "    y_pred = model.predict(np.array([x]))\n",
    "    print(f\"Input: {x} => Predicted: {round(y_pred[0][0])} (Raw: {y_pred[0][0]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71369e9c-8b45-4439-ab7c-23aa1eebb598",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: '\\u202aC:/Users/Pradnya/Downloads/wine_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mâ€ªC:/Users/Pradnya/Downloads/wine_data.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(data.head())\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Split features and labels\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mOSError\u001b[39m: [Errno 22] Invalid argument: '\\u202aC:/Users/Pradnya/Downloads/wine_data.csv'"
     ]
    }
   ],
   "source": [
    "#using CSV file \n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('â€ªC:/Users/Pradnya/Downloads/wine_data.csv')\n",
    "print(data.head())\n",
    "\n",
    "# Split features and labels\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.01, random_state=42)\n",
    "\n",
    "# Define RBF kernel function\n",
    "def rbf_kernel(x1, x2, gamma=1.0):\n",
    "    diff = x1 - x2\n",
    "    return np.exp(-gamma * np.dot(diff, diff.T))\n",
    "\n",
    "# Define RBF classifier using nearest center approach\n",
    "def rbf_classifier(X_train, y_train, X_test, gamma):\n",
    "    predictions = []\n",
    "    \n",
    "    for test_sample in X_test:\n",
    "        distances = []\n",
    "        for train_sample in X_train:\n",
    "            distance = rbf_kernel(test_sample, train_sample, gamma)\n",
    "            distances.append(distance)\n",
    "        \n",
    "        closest_index = np.argmax(distances)\n",
    "        predictions.append(y_train[closest_index])\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "# Run classifier\n",
    "predictions = rbf_classifier(X_train, y_train, X_test, gamma=0.5)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d34c0e2-c635-4e5d-9cbd-3f69984a21d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\pradnya\\appdata\\roaming\\python\\python312\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\pradnya\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\pradnya\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\pradnya\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\pradnya\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eabb14f-3f66-4725-ac9d-ce0d9e30e805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  balance  day  duration  campaign  pdays  previous  job  marital  \\\n",
      "0   58     2143    5       261         1     -1         0    4        1   \n",
      "1   44       29    5       151         1     -1         0    9        2   \n",
      "2   33        2    5        76         1     -1         0    2        1   \n",
      "3   47     1506    5        92         1     -1         0    1        1   \n",
      "4   33        1    5       198         1     -1         0   11        2   \n",
      "\n",
      "   education  default  housing  loan  contact  month  poutcome  y  \n",
      "0          2        0        1     0        2      8         3  0  \n",
      "1          1        0        1     0        2      8         3  0  \n",
      "2          1        0        1     1        2      8         3  0  \n",
      "3          3        0        1     0        2      8         3  0  \n",
      "4          3        0        0     0        2      8         3  0  \n",
      "4.0\n",
      "[[0.43087774 0.51788175 0.87246038 ... 0.56174452 0.58393056 0.60717375]\n",
      " [0.60268249 0.7841429  0.67667375 ... 0.77370279 0.87499958 0.77226672]\n",
      " [0.68070106 0.76028363 0.70914173 ... 0.77669407 0.88487566 0.81105823]\n",
      " ...\n",
      " [0.50895774 0.64113    0.62454418 ... 0.84164331 0.74869943 0.72777683]\n",
      " [0.55389169 0.68249185 0.66050806 ... 0.76071181 0.77139876 0.88108461]\n",
      " [0.61741537 0.73253633 0.68677768 ... 0.78080112 0.89768974 0.79614458]]\n",
      "[ 0.15473     2.01572308  0.18418342 -0.14934428 -0.09256463 -0.42366364\n",
      " -0.137665   -1.1833642 ]\n",
      "[0.56354255 0.69204346 0.66864378 0.69889976 0.91436516 0.77484913\n",
      " 0.84561816 0.78828492]\n",
      "0.8911793329204636\n"
     ]
    }
   ],
   "source": [
    "#using bank dataset by kmeans\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load and preprocess data\n",
    "Data = pd.read_csv(\"C:/Users/Pradnya/Downloads/bank-full.csv\")\n",
    "cols = [\"age\", \"balance\", \"day\", \"duration\", \"campaign\", \"pdays\", \"previous\"]\n",
    "data_encode = Data.drop(cols, axis=1)\n",
    "data_encode = data_encode.apply(LabelEncoder().fit_transform)\n",
    "data_rest = Data[cols]\n",
    "Data = pd.concat([data_rest, data_encode], axis=1)\n",
    "print(Data.head())\n",
    "\n",
    "# Train-test split\n",
    "data_train, data_test = train_test_split(Data, test_size=0.5, random_state=4)\n",
    "x_train = data_train.drop(\"y\", axis=1)\n",
    "y_train = data_train[\"y\"]\n",
    "x_test = data_test.drop(\"y\", axis=1)\n",
    "y_test = data_test[\"y\"]\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "# KMeans for center selection\n",
    "K_cent = 8\n",
    "km = KMeans(n_clusters=K_cent, max_iter=98)\n",
    "km.fit(x_train)\n",
    "cent = km.cluster_centers_\n",
    "\n",
    "# Compute sigma\n",
    "max_d = 0\n",
    "for i in range(K_cent):\n",
    "    for j in range(K_cent):\n",
    "        d = np.linalg.norm(cent[i] - cent[j])\n",
    "        if d > max_d:\n",
    "            max_d = d\n",
    "sigma = math.sqrt(2 * K_cent)\n",
    "print(sigma)\n",
    "\n",
    "# Compute RBF feature matrix for training set\n",
    "shape = x_train.shape\n",
    "row = shape[0]\n",
    "column = K_cent\n",
    "G = np.empty((row, column), dtype=float)\n",
    "\n",
    "for i in range(row):\n",
    "    for j in range(column):\n",
    "        dist = np.linalg.norm(x_train[i] - cent[j])\n",
    "        G[i][j] = math.exp(-math.pow(dist, 2) / math.pow(2 * sigma, 2))\n",
    "\n",
    "print(G)\n",
    "\n",
    "# Compute weights using pseudo-inverse\n",
    "GTG = np.dot(G.T, G)\n",
    "GTG_inv = np.linalg.inv(GTG)\n",
    "fac = np.dot(GTG_inv, G.T)\n",
    "w = np.dot(fac, y_train)\n",
    "print(w)\n",
    "\n",
    "# Compute RBF features for test data\n",
    "row = x_test.shape[0]\n",
    "G_test = np.empty((row, column), dtype=float)\n",
    "\n",
    "for i in range(row):\n",
    "    for j in range(column):\n",
    "        dist = np.linalg.norm(x_test[i] - cent[j])\n",
    "        G_test[i][j] = math.exp(-math.pow(dist, 2) / math.pow(2 * sigma, 2))\n",
    "\n",
    "print(G_test[0])\n",
    "\n",
    "# Predict\n",
    "prediction = np.dot(G_test, w)\n",
    "prediction = 0.5 * (np.sign(prediction - 0.5) + 1)\n",
    "score = accuracy_score(y_test, prediction)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3230f116-e3c7-48c1-ae80-b898327db1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma: 1.9995327534016647\n",
      "Design Matrix G (Training):\n",
      " [[0.57937708 0.16097536 0.62094693 0.49965058]\n",
      " [0.74489523 0.12076463 0.71525592 0.72719415]\n",
      " [0.76068914 0.08221137 0.71548549 0.59259208]\n",
      " ...\n",
      " [0.75386671 0.22365074 0.74507257 0.88156271]\n",
      " [0.54099646 0.21057158 0.56798261 0.65235794]\n",
      " [0.68447479 0.15622313 0.64614765 0.84755221]]\n",
      "Weights:\n",
      " [2.54824158 5.63297371 2.46945749 2.83679068]\n",
      "First Row of G_test:\n",
      " [0.42969109 0.07257094 0.43285739 0.65395114]\n",
      "Predictions:\n",
      " [3. 3. 3. ... 3. 3. 3.]\n",
      "Actual:\n",
      " 5159     4\n",
      "16697    8\n",
      "7588     5\n",
      "11120    6\n",
      "16980    8\n",
      "        ..\n",
      "12030    7\n",
      "10301    6\n",
      "18763    9\n",
      "9532     6\n",
      "20917    9\n",
      "Name: quality, Length: 10500, dtype: int64\n",
      "Accuracy Score: 0.14876190476190476\n"
     ]
    }
   ],
   "source": [
    "#using wine dataset for kmeans\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"C:/Users/Pradnya/Downloads/wine_data.csv\")\n",
    "\n",
    "# Split dataset\n",
    "data_train, data_test = train_test_split(data, test_size=0.5, random_state=4)\n",
    "x_train = data_train.drop(\"quality\", axis=1)\n",
    "y_train = data_train[\"quality\"]\n",
    "x_test = data_test.drop(\"quality\", axis=1)\n",
    "y_test = data_test[\"quality\"]\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# KMeans Clustering\n",
    "K_cent = 4\n",
    "km = KMeans(n_clusters=K_cent, max_iter=98)\n",
    "km.fit(x_train)\n",
    "cent = km.cluster_centers_\n",
    "\n",
    "# Calculate sigma\n",
    "max_dist = 0\n",
    "for i in range(K_cent):\n",
    "    for j in range(K_cent):\n",
    "        d = np.linalg.norm(cent[i] - cent[j])\n",
    "        if d > max_dist:\n",
    "            max_dist = d\n",
    "\n",
    "# Fix for division by zero\n",
    "if max_dist == 0:\n",
    "    sigma = 1e-6  # small fallback value\n",
    "else:\n",
    "    sigma = max_dist / math.sqrt(2 * K_cent)\n",
    "\n",
    "print(\"Sigma:\", sigma)\n",
    "\n",
    "# Build design matrix G for training set\n",
    "shape = x_train.shape\n",
    "row = shape[0]\n",
    "column = K_cent\n",
    "G = np.empty((row, column), dtype=float)\n",
    "\n",
    "for i in range(row):\n",
    "    for j in range(column):\n",
    "        dist = np.linalg.norm(x_train[i] - cent[j])\n",
    "        G[i][j] = math.exp(-math.pow(dist, 2) / math.pow(2 * sigma, 2))\n",
    "\n",
    "print(\"Design Matrix G (Training):\\n\", G)\n",
    "\n",
    "# Train Weights using Least Squares\n",
    "GTG = np.dot(G.T, G)\n",
    "GTG_inv = np.linalg.inv(GTG)\n",
    "fac = np.dot(GTG_inv, G.T)\n",
    "w = np.dot(fac, y_train)\n",
    "print(\"Weights:\\n\", w)\n",
    "\n",
    "# Build design matrix G_test for testing set\n",
    "row = x_test.shape[0]\n",
    "G_test = np.empty((row, column), dtype=float)\n",
    "\n",
    "for i in range(row):\n",
    "    for j in range(column):\n",
    "        dist = np.linalg.norm(x_test[i] - cent[j])\n",
    "        G_test[i][j] = math.exp(-math.pow(dist, 2) / math.pow(2 * sigma, 2))\n",
    "\n",
    "print(\"First Row of G_test:\\n\", G_test[0])\n",
    "\n",
    "# Predict\n",
    "prediction = np.dot(G_test, w)\n",
    "prediction = 0.5 * (np.sign(prediction - 0.5) + 5)\n",
    "print(\"Predictions:\\n\", prediction)\n",
    "print(\"Actual:\\n\", y_test)\n",
    "\n",
    "# Accuracy\n",
    "score = accuracy_score(y_test, prediction)\n",
    "print(\"Accuracy Score:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bfce40-d680-496c-b752-6208bc2127fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
